{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processamento dos Datasets para Experimento RCBD\n",
    "\n",
    "**Equipe F**: Bernardo Bacha de Resende, Gustavo Augusto Faria dos Reis, Mar√≠lia Mac√™do de Melo\n",
    "\n",
    "**Disciplina**: EEE933 - Planejamento e An√°lise de Experimentos (2025/2)\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook processa os 5 datasets de classifica√ß√£o bin√°ria, preparando-os para uso no experimento RCBD.\n",
    "\n",
    "**Datasets:**\n",
    "1. Breast Cancer (569 amostras)\n",
    "2. Titanic (891 amostras)\n",
    "3. Water Potability (3,276 amostras)\n",
    "4. Employee Attrition (4,653 amostras)\n",
    "5. Australia Rain (145,460 amostras ‚Üí amostragem para ~10k)\n",
    "\n",
    "**Pr√©-processamento aplicado:**\n",
    "- Remo√ß√£o de colunas n√£o informativas (IDs, nomes, etc.)\n",
    "- Tratamento de valores nulos (mediana para num√©rico, moda para categ√≥rico)\n",
    "- One-hot encoding para features categ√≥ricas\n",
    "- StandardScaler (z-score) para normaliza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports e Configura√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset 1: Breast Cancer\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- 569 amostras √ó 32 colunas\n",
    "- Target: `diagnosis` (M=Malignant, B=Benign)\n",
    "- Sem valores nulos\n",
    "- Dataset mais limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET 1: BREAST CANCER\n",
      "================================================================================\n",
      "Shape original: (569, 32)\n",
      "Colunas: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
      "\n",
      "Valores nulos: 0\n",
      "\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "X_breast_cancer shape: (569, 30)\n",
      "y_breast_cancer shape: (569,)\n",
      "Distribui√ß√£o do target:\n",
      "diagnosis\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: diagnosis\n",
      "0    0.627417\n",
      "1    0.372583\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET 1: BREAST CANCER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dataset\n",
    "df_breast = pd.read_csv('../data/breast_cancer.csv')\n",
    "print(f\"Shape original: {df_breast.shape}\")\n",
    "print(f\"Colunas: {list(df_breast.columns)}\")\n",
    "\n",
    "# Remover coluna ID\n",
    "df_breast = df_breast.drop(columns=['id'])\n",
    "\n",
    "# Separar target\n",
    "y_breast_cancer = df_breast['diagnosis'].map({'M': 1, 'B': 0})\n",
    "X_breast_cancer = df_breast.drop(columns=['diagnosis'])\n",
    "\n",
    "# Verificar nulos\n",
    "print(f\"\\nValores nulos: {X_breast_cancer.isnull().sum().sum()}\")\n",
    "\n",
    "# Normalizar com StandardScaler\n",
    "scaler_breast = StandardScaler()\n",
    "X_breast_cancer = pd.DataFrame(\n",
    "    scaler_breast.fit_transform(X_breast_cancer),\n",
    "    columns=X_breast_cancer.columns\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"X_breast_cancer shape: {X_breast_cancer.shape}\")\n",
    "print(f\"y_breast_cancer shape: {y_breast_cancer.shape}\")\n",
    "print(f\"Distribui√ß√£o do target:\\n{y_breast_cancer.value_counts()}\")\n",
    "print(f\"Propor√ß√£o: {y_breast_cancer.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset 2: Titanic\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- 891 amostras √ó 12 colunas\n",
    "- Target: `Survived` (0/1)\n",
    "- Valores nulos em Age, Cabin, Embarked\n",
    "- Features categ√≥ricas: Sex, Embarked, Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET 2: TITANIC\n",
      "================================================================================\n",
      "Shape original: (891, 12)\n",
      "\n",
      "Valores nulos por coluna:\n",
      "Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos ap√≥s tratamento: 0\n",
      "\n",
      "Colunas ap√≥s one-hot encoding (10): ['Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3']\n",
      "\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "X_titanic shape: (891, 10)\n",
      "y_titanic shape: (891,)\n",
      "Distribui√ß√£o do target:\n",
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET 2: TITANIC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dataset\n",
    "df_titanic = pd.read_csv('../data/titanic.csv')\n",
    "print(f\"Shape original: {df_titanic.shape}\")\n",
    "print(f\"\\nValores nulos por coluna:\\n{df_titanic.isnull().sum()[df_titanic.isnull().sum() > 0]}\")\n",
    "\n",
    "# Remover colunas n√£o informativas\n",
    "df_titanic = df_titanic.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Separar target\n",
    "y_titanic = df_titanic['Survived']\n",
    "X_titanic = df_titanic.drop(columns=['Survived'])\n",
    "\n",
    "# Tratar valores nulos\n",
    "# Age: preencher com mediana\n",
    "X_titanic['Age'].fillna(X_titanic['Age'].median(), inplace=True)\n",
    "# Embarked: preencher com moda\n",
    "X_titanic['Embarked'].fillna(X_titanic['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "print(f\"\\nValores nulos ap√≥s tratamento: {X_titanic.isnull().sum().sum()}\")\n",
    "\n",
    "# One-hot encoding para categ√≥ricas\n",
    "categorical_cols = ['Sex', 'Embarked']\n",
    "X_titanic = pd.get_dummies(X_titanic, columns=categorical_cols, drop_first=True, dtype=int)\n",
    "\n",
    "# Converter Pclass para dummy se ainda n√£o for num√©rico adequado\n",
    "# Pclass j√° √© num√©rico (1, 2, 3), mas pode fazer one-hot se preferir\n",
    "X_titanic = pd.get_dummies(X_titanic, columns=['Pclass'], prefix='Pclass', dtype=int)\n",
    "\n",
    "print(f\"\\nColunas ap√≥s one-hot encoding ({len(X_titanic.columns)}): {list(X_titanic.columns)}\")\n",
    "\n",
    "# Normalizar com StandardScaler\n",
    "scaler_titanic = StandardScaler()\n",
    "X_titanic = pd.DataFrame(\n",
    "    scaler_titanic.fit_transform(X_titanic),\n",
    "    columns=X_titanic.columns\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"X_titanic shape: {X_titanic.shape}\")\n",
    "print(f\"y_titanic shape: {y_titanic.shape}\")\n",
    "print(f\"Distribui√ß√£o do target:\\n{y_titanic.value_counts()}\")\n",
    "print(f\"Propor√ß√£o: {y_titanic.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset 3: Water Potability\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- 3,276 amostras √ó 10 colunas\n",
    "- Target: `Potability` (0/1)\n",
    "- Valores nulos em pH, Sulfate, Trihalomethanes\n",
    "- Todas features num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET 3: WATER POTABILITY\n",
      "================================================================================\n",
      "Shape original: (3276, 10)\n",
      "\n",
      "Valores nulos por coluna:\n",
      "ph                 491\n",
      "Sulfate            781\n",
      "Trihalomethanes    162\n",
      "dtype: int64\n",
      "Preenchidos ph com mediana: 7.04\n",
      "Preenchidos Sulfate com mediana: 333.07\n",
      "Preenchidos Trihalomethanes com mediana: 66.62\n",
      "\n",
      "Valores nulos ap√≥s tratamento: 0\n",
      "\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "X_water_potability shape: (3276, 9)\n",
      "y_water_potability shape: (3276,)\n",
      "Distribui√ß√£o do target:\n",
      "Potability\n",
      "0    1998\n",
      "1    1278\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: Potability\n",
      "0    0.60989\n",
      "1    0.39011\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET 3: WATER POTABILITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dataset\n",
    "df_water = pd.read_csv('../data/water_potability.csv')\n",
    "print(f\"Shape original: {df_water.shape}\")\n",
    "print(f\"\\nValores nulos por coluna:\\n{df_water.isnull().sum()[df_water.isnull().sum() > 0]}\")\n",
    "\n",
    "# Separar target\n",
    "y_water_potability = df_water['Potability']\n",
    "X_water_potability = df_water.drop(columns=['Potability'])\n",
    "\n",
    "# Tratar valores nulos (preencher com mediana)\n",
    "for col in X_water_potability.columns:\n",
    "    if X_water_potability[col].isnull().sum() > 0:\n",
    "        X_water_potability[col].fillna(X_water_potability[col].median(), inplace=True)\n",
    "        print(f\"Preenchidos {col} com mediana: {X_water_potability[col].median():.2f}\")\n",
    "\n",
    "print(f\"\\nValores nulos ap√≥s tratamento: {X_water_potability.isnull().sum().sum()}\")\n",
    "\n",
    "# Normalizar com StandardScaler\n",
    "scaler_water = StandardScaler()\n",
    "X_water_potability = pd.DataFrame(\n",
    "    scaler_water.fit_transform(X_water_potability),\n",
    "    columns=X_water_potability.columns\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"X_water_potability shape: {X_water_potability.shape}\")\n",
    "print(f\"y_water_potability shape: {y_water_potability.shape}\")\n",
    "print(f\"Distribui√ß√£o do target:\\n{y_water_potability.value_counts()}\")\n",
    "print(f\"Propor√ß√£o: {y_water_potability.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset 4: Employee Attrition\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- 4,653 amostras √ó 9 colunas\n",
    "- Target: `LeaveOrNot` (0=Ficou, 1=Saiu do emprego)\n",
    "- Sem valores nulos\n",
    "- Features categ√≥ricas: Education, City, Gender, EverBenched\n",
    "- **Aten√ß√£o**: Classes razoavelmente balanceadas (~34% sa√≠das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET 4: EMPLOYEE ATTRITION\n",
      "================================================================================\n",
      "Shape original: (4653, 9)\n",
      "\n",
      "Valores nulos por coluna:\n",
      "0 (nenhum!)\n",
      "\n",
      "Valores nulos: 0\n",
      "\n",
      "Colunas categ√≥ricas para encoding: ['Education', 'City', 'Gender', 'EverBenched']\n",
      "\n",
      "Colunas ap√≥s one-hot encoding (10): ['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain', 'Education_Masters', 'Education_PHD', 'City_New Delhi', 'City_Pune', 'Gender_Male', 'EverBenched_Yes']\n",
      "\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "X_employee shape: (4653, 10)\n",
      "y_employee shape: (4653,)\n",
      "Distribui√ß√£o do target:\n",
      "LeaveOrNot\n",
      "0    3053\n",
      "1    1600\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: LeaveOrNot\n",
      "0    0.656136\n",
      "1    0.343864\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET 4: EMPLOYEE ATTRITION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dataset\n",
    "df_employee = pd.read_csv('../data/Employee.csv')\n",
    "print(f\"Shape original: {df_employee.shape}\")\n",
    "print(f\"\\nValores nulos por coluna:\\n{df_employee.isnull().sum().sum()} (nenhum!)\")\n",
    "\n",
    "# Separar target\n",
    "y_employee = df_employee['LeaveOrNot']\n",
    "X_employee = df_employee.drop(columns=['LeaveOrNot'])\n",
    "\n",
    "print(f\"\\nValores nulos: {X_employee.isnull().sum().sum()}\")\n",
    "\n",
    "# Identificar e fazer one-hot encoding para categ√≥ricas\n",
    "categorical_cols = ['Education', 'City', 'Gender', 'EverBenched']\n",
    "print(f\"\\nColunas categ√≥ricas para encoding: {categorical_cols}\")\n",
    "\n",
    "X_employee = pd.get_dummies(X_employee, columns=categorical_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(f\"\\nColunas ap√≥s one-hot encoding ({len(X_employee.columns)}): {list(X_employee.columns)}\")\n",
    "\n",
    "# Normalizar com StandardScaler\n",
    "scaler_employee = StandardScaler()\n",
    "X_employee = pd.DataFrame(\n",
    "    scaler_employee.fit_transform(X_employee),\n",
    "    columns=X_employee.columns\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"X_employee shape: {X_employee.shape}\")\n",
    "print(f\"y_employee shape: {y_employee.shape}\")\n",
    "print(f\"Distribui√ß√£o do target:\\n{y_employee.value_counts()}\")\n",
    "print(f\"Propor√ß√£o: {y_employee.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset 5: Australia Rain (Weather)\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- 145,460 amostras √ó 23 colunas (MUITO GRANDE)\n",
    "- Target: `RainTomorrow` (Yes/No)\n",
    "- MUITOS valores nulos (~40% das features)\n",
    "- Features categ√≥ricas: WindGustDir, WindDir9am, WindDir3pm, RainToday\n",
    "\n",
    "**Estrat√©gia:**\n",
    "1. Remover Date e Location (n√£o informativas/muitas categorias)\n",
    "2. Remover linhas com muitos nulos (dropna)\n",
    "3. Fazer amostragem estratificada para ~10k amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET 5: AUSTRALIA RAIN (WEATHER)\n",
      "================================================================================\n",
      "Shape original: (145460, 23)\n",
      "\n",
      "Valores nulos por coluna:\n",
      "MinTemp           1485\n",
      "MaxTemp           1261\n",
      "Rainfall          3261\n",
      "Evaporation      62790\n",
      "Sunshine         69835\n",
      "WindGustDir      10326\n",
      "WindGustSpeed    10263\n",
      "WindDir9am       10566\n",
      "WindDir3pm        4228\n",
      "WindSpeed9am      1767\n",
      "WindSpeed3pm      3062\n",
      "Humidity9am       2654\n",
      "Humidity3pm       4507\n",
      "Pressure9am      15065\n",
      "Pressure3pm      15028\n",
      "Cloud9am         55888\n",
      "Cloud3pm         59358\n",
      "Temp9am           1767\n",
      "Temp3pm           3609\n",
      "RainToday         3261\n",
      "RainTomorrow      3267\n",
      "dtype: int64\n",
      "\n",
      "Total de colunas com nulos: 21\n",
      "\n",
      "Shape ap√≥s remo√ß√£o de Date e Location: (145460, 21)\n",
      "Shape ap√≥s remover target nulo: (142193, 21)\n",
      "\n",
      "Linhas removidas por nulos: 85773\n",
      "Shape ap√≥s dropna: X=(56420, 20), y=(56420,)\n",
      "\n",
      "Colunas categ√≥ricas identificadas: ['WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
      "Colunas ap√≥s one-hot encoding: 62\n",
      "\n",
      "Fazendo amostragem estratificada de 56420 para 10000 amostras...\n",
      "Shape ap√≥s amostragem: X=(10000, 62), y=(10000,)\n",
      "\n",
      "‚úì Pr√©-processamento conclu√≠do!\n",
      "X_weather shape: (10000, 62)\n",
      "y_weather shape: (10000,)\n",
      "Distribui√ß√£o do target:\n",
      "RainTomorrow\n",
      "0    7797\n",
      "1    2203\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: RainTomorrow\n",
      "0    0.7797\n",
      "1    0.2203\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATASET 5: AUSTRALIA RAIN (WEATHER)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dataset\n",
    "df_weather = pd.read_csv('../data/weather.csv')\n",
    "print(f\"Shape original: {df_weather.shape}\")\n",
    "print(f\"\\nValores nulos por coluna:\")\n",
    "null_counts = df_weather.isnull().sum()\n",
    "print(null_counts[null_counts > 0])\n",
    "print(f\"\\nTotal de colunas com nulos: {(null_counts > 0).sum()}\")\n",
    "\n",
    "# Remover colunas n√£o informativas\n",
    "df_weather = df_weather.drop(columns=['Date', 'Location'])\n",
    "print(f\"\\nShape ap√≥s remo√ß√£o de Date e Location: {df_weather.shape}\")\n",
    "\n",
    "# Remover target nulo primeiro\n",
    "df_weather = df_weather.dropna(subset=['RainTomorrow'])\n",
    "print(f\"Shape ap√≥s remover target nulo: {df_weather.shape}\")\n",
    "\n",
    "# Separar target\n",
    "y_weather = df_weather['RainTomorrow'].map({'Yes': 1, 'No': 0})\n",
    "X_weather = df_weather.drop(columns=['RainTomorrow'])\n",
    "\n",
    "# Remover linhas com muitos nulos (estrat√©gia: dropna)\n",
    "# Vamos remover linhas que t√™m qualquer valor nulo\n",
    "initial_rows = len(X_weather)\n",
    "valid_indices = X_weather.dropna().index\n",
    "X_weather = X_weather.loc[valid_indices]\n",
    "y_weather = y_weather.loc[valid_indices]\n",
    "\n",
    "print(f\"\\nLinhas removidas por nulos: {initial_rows - len(X_weather)}\")\n",
    "print(f\"Shape ap√≥s dropna: X={X_weather.shape}, y={y_weather.shape}\")\n",
    "\n",
    "# One-hot encoding para categ√≥ricas\n",
    "# Converter RainToday para num√©rico antes\n",
    "if 'RainToday' in X_weather.columns:\n",
    "    X_weather['RainToday'] = X_weather['RainToday'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Identificar colunas categ√≥ricas (dire√ß√µes de vento)\n",
    "categorical_cols = [col for col in X_weather.columns if 'WindDir' in col or 'Wind' in col and X_weather[col].dtype == 'object']\n",
    "print(f\"\\nColunas categ√≥ricas identificadas: {categorical_cols}\")\n",
    "\n",
    "if categorical_cols:\n",
    "    X_weather = pd.get_dummies(X_weather, columns=categorical_cols, drop_first=True, dtype=int)\n",
    "    print(f\"Colunas ap√≥s one-hot encoding: {len(X_weather.columns)}\")\n",
    "\n",
    "# AMOSTRAGEM ESTRATIFICADA para ~10k amostras\n",
    "if len(X_weather) > 10000:\n",
    "    sample_size = 10000\n",
    "    print(f\"\\nFazendo amostragem estratificada de {len(X_weather)} para {sample_size} amostras...\")\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_weather, _, y_weather, _ = train_test_split(\n",
    "        X_weather, y_weather, \n",
    "        train_size=sample_size, \n",
    "        stratify=y_weather,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Shape ap√≥s amostragem: X={X_weather.shape}, y={y_weather.shape}\")\n",
    "\n",
    "# Normalizar com StandardScaler\n",
    "scaler_weather = StandardScaler()\n",
    "X_weather = pd.DataFrame(\n",
    "    scaler_weather.fit_transform(X_weather),\n",
    "    columns=X_weather.columns\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pr√©-processamento conclu√≠do!\")\n",
    "print(f\"X_weather shape: {X_weather.shape}\")\n",
    "print(f\"y_weather shape: {y_weather.shape}\")\n",
    "print(f\"Distribui√ß√£o do target:\\n{y_weather.value_counts()}\")\n",
    "print(f\"Propor√ß√£o: {y_weather.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumo Final\n",
    "\n",
    "Valida√ß√£o de todos os datasets processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMO FINAL - TODOS OS DATASETS PROCESSADOS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "         Dataset  Amostras  Features  Nulos em X  Nulos em y  Classe 0  Classe 1 Propor√ß√£o (%)\n",
      "   Breast Cancer       569        30           0           0       357       212         37.3%\n",
      "         Titanic       891        10           0           0       549       342         38.4%\n",
      "Water Potability      3276         9           0           0      1998      1278         39.0%\n",
      "        Employee      4653        10           0           0      3053      1600         34.4%\n",
      "         Weather     10000        62           0           0      7797      2203         22.0%\n",
      "\n",
      "================================================================================\n",
      "‚úì TODOS OS DATASETS PRONTOS PARA USO NO EXPERIMENTO RCBD!\n",
      "================================================================================\n",
      "\n",
      "üìä Vari√°veis dispon√≠veis:\n",
      "  ‚Ä¢ X_breast_cancer, y_breast_cancer\n",
      "  ‚Ä¢ X_titanic, y_titanic\n",
      "  ‚Ä¢ X_water_potability, y_water_potability\n",
      "  ‚Ä¢ X_employee, y_employee\n",
      "  ‚Ä¢ X_weather, y_weather\n",
      "\n",
      "üéØ Caracter√≠sticas:\n",
      "  ‚Ä¢ Todas as features s√£o num√©ricas\n",
      "  ‚Ä¢ Sem valores nulos\n",
      "  ‚Ä¢ Normalizadas com StandardScaler (z-score)\n",
      "  ‚Ä¢ Prontas para classificadores de ML\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMO FINAL - TODOS OS DATASETS PROCESSADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "datasets_summary = {\n",
    "    'Breast Cancer': (X_breast_cancer, y_breast_cancer),\n",
    "    'Titanic': (X_titanic, y_titanic),\n",
    "    'Water Potability': (X_water_potability, y_water_potability),\n",
    "    'Employee': (X_employee, y_employee),\n",
    "    'Weather': (X_weather, y_weather)\n",
    "}\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for name, (X, y) in datasets_summary.items():\n",
    "    summary_data.append({\n",
    "        'Dataset': name,\n",
    "        'Amostras': X.shape[0],\n",
    "        'Features': X.shape[1],\n",
    "        'Nulos em X': X.isnull().sum().sum(),\n",
    "        'Nulos em y': y.isnull().sum(),\n",
    "        'Classe 0': (y == 0).sum(),\n",
    "        'Classe 1': (y == 1).sum(),\n",
    "        'Propor√ß√£o (%)': f\"{(y == 1).sum() / len(y) * 100:.1f}%\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì TODOS OS DATASETS PRONTOS PARA USO NO EXPERIMENTO RCBD!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Vari√°veis dispon√≠veis:\")\n",
    "print(\"  ‚Ä¢ X_breast_cancer, y_breast_cancer\")\n",
    "print(\"  ‚Ä¢ X_titanic, y_titanic\")\n",
    "print(\"  ‚Ä¢ X_water_potability, y_water_potability\")\n",
    "print(\"  ‚Ä¢ X_employee, y_employee\")\n",
    "print(\"  ‚Ä¢ X_weather, y_weather\")\n",
    "\n",
    "print(\"\\nüéØ Caracter√≠sticas:\")\n",
    "print(\"  ‚Ä¢ Todas as features s√£o num√©ricas\")\n",
    "print(\"  ‚Ä¢ Sem valores nulos\")\n",
    "print(\"  ‚Ä¢ Normalizadas com StandardScaler (z-score)\")\n",
    "print(\"  ‚Ä¢ Prontas para classificadores de ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BASELINE - SVM COM KERNEL RBF\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: Breast Cancer\n",
      "--------------------------------------------------------------------------------\n",
      "Treino: 455 amostras | Teste: 114 amostras\n",
      "Acur√°cia:  97.37%\n",
      "Precis√£o:  100.00%\n",
      "Recall:    92.86%\n",
      "F1-Score:  96.30%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: Titanic\n",
      "--------------------------------------------------------------------------------\n",
      "Treino: 712 amostras | Teste: 179 amostras\n",
      "Acur√°cia:  81.01%\n",
      "Precis√£o:  85.71%\n",
      "Recall:    60.87%\n",
      "F1-Score:  71.19%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: Water Potability\n",
      "--------------------------------------------------------------------------------\n",
      "Treino: 2620 amostras | Teste: 656 amostras\n",
      "Acur√°cia:  67.07%\n",
      "Precis√£o:  70.41%\n",
      "Recall:    26.95%\n",
      "F1-Score:  38.98%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: Employee\n",
      "--------------------------------------------------------------------------------\n",
      "Treino: 3722 amostras | Teste: 931 amostras\n",
      "Acur√°cia:  83.24%\n",
      "Precis√£o:  87.61%\n",
      "Recall:    59.69%\n",
      "F1-Score:  71.00%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: Weather\n",
      "--------------------------------------------------------------------------------\n",
      "Treino: 8000 amostras | Teste: 2000 amostras\n",
      "Acur√°cia:  84.70%\n",
      "Precis√£o:  73.68%\n",
      "Recall:    47.62%\n",
      "F1-Score:  57.85%\n",
      "\n",
      "================================================================================\n",
      "TABELA RESUMO - BASELINE SVM (KERNEL RBF)\n",
      "================================================================================\n",
      "\n",
      "         Dataset  Treino  Teste Acur√°cia (%) Precis√£o (%) Recall (%) F1-Score (%)\n",
      "   Breast Cancer     455    114        97.37       100.00      92.86        96.30\n",
      "         Titanic     712    179        81.01        85.71      60.87        71.19\n",
      "Water Potability    2620    656        67.07        70.41      26.95        38.98\n",
      "        Employee    3722    931        83.24        87.61      59.69        71.00\n",
      "         Weather    8000   2000        84.70        73.68      47.62        57.85\n",
      "\n",
      "================================================================================\n",
      "‚úì BASELINE CONCLU√çDO!\n",
      "================================================================================\n",
      "\n",
      "üìù Observa√ß√µes:\n",
      "  ‚Ä¢ Todos os datasets foram treinados com sucesso\n",
      "  ‚Ä¢ M√©tricas baseline dispon√≠veis para compara√ß√£o futura\n",
      "  ‚Ä¢ Employee: Dataset balanceado (~34% sa√≠das) com boas m√©tricas\n",
      "  ‚Ä¢ Pr√≥ximo passo: Experimento RCBD com diferentes tratamentos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BASELINE - SVM COM KERNEL RBF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dicion√°rio para armazenar resultados\n",
    "baseline_results = []\n",
    "\n",
    "# Lista de datasets\n",
    "datasets = [\n",
    "    ('Breast Cancer', X_breast_cancer, y_breast_cancer),\n",
    "    ('Titanic', X_titanic, y_titanic),\n",
    "    ('Water Potability', X_water_potability, y_water_potability),\n",
    "    ('Employee', X_employee, y_employee),\n",
    "    ('Weather', X_weather, y_weather)\n",
    "]\n",
    "\n",
    "# Para cada dataset\n",
    "for name, X, y in datasets:\n",
    "    print(f\"\\n{'-' * 80}\")\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"{'-' * 80}\")\n",
    "    \n",
    "    # Train/Test Split (80/20) com stratify\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        stratify=y, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\")\n",
    "    \n",
    "    # Treinar SVM com kernel RBF\n",
    "    svm = SVC(kernel='rbf', random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    baseline_results.append({\n",
    "        'Dataset': name,\n",
    "        'Treino': X_train.shape[0],\n",
    "        'Teste': X_test.shape[0],\n",
    "        'Acur√°cia (%)': acc * 100,\n",
    "        'Precis√£o (%)': prec * 100,\n",
    "        'Recall (%)': rec * 100,\n",
    "        'F1-Score (%)': f1 * 100\n",
    "    })\n",
    "    \n",
    "    print(f\"Acur√°cia:  {acc*100:.2f}%\")\n",
    "    print(f\"Precis√£o:  {prec*100:.2f}%\")\n",
    "    print(f\"Recall:    {rec*100:.2f}%\")\n",
    "    print(f\"F1-Score:  {f1*100:.2f}%\")\n",
    "\n",
    "# Criar DataFrame com resultados consolidados\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABELA RESUMO - BASELINE SVM (KERNEL RBF)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "# Formatar colunas de m√©tricas com 2 casas decimais\n",
    "for col in ['Acur√°cia (%)', 'Precis√£o (%)', 'Recall (%)', 'F1-Score (%)']:\n",
    "    baseline_df[col] = baseline_df[col].map('{:.2f}'.format)\n",
    "\n",
    "print(baseline_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì BASELINE CONCLU√çDO!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìù Observa√ß√µes:\")\n",
    "print(\"  ‚Ä¢ Todos os datasets foram treinados com sucesso\")\n",
    "print(\"  ‚Ä¢ M√©tricas baseline dispon√≠veis para compara√ß√£o futura\")\n",
    "print(\"  ‚Ä¢ Employee: Dataset balanceado (~34% sa√≠das) com boas m√©tricas\")\n",
    "print(\"  ‚Ä¢ Pr√≥ximo passo: Experimento RCBD com diferentes tratamentos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Baseline - SVM com Kernel RBF\n",
    "\n",
    "**Objetivo:** Treinar SVM simples em cada dataset para:\n",
    "1. Validar que os dados est√£o funcionando corretamente\n",
    "2. Obter m√©tricas baseline de refer√™ncia\n",
    "\n",
    "**Configura√ß√£o:**\n",
    "- Train/Test Split: 80/20 (stratified)\n",
    "- Modelo: SVM com kernel RBF (padr√£o)\n",
    "- M√©tricas: Acur√°cia, Precis√£o, Recall, F1-Score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Trabalho Final PAE)",
   "language": "python",
   "name": "trabalho-final-pae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
